Here is a simple implementation of the k-Nearest Neighbors (k-NN) algorithm for classification using Python:

```python
import numpy as np
from collections import Counter
from scipy.spatial.distance import euclidean

class KNearestNeighbors:
    def __init__(self, k=3):
        self.k = k

    def fit(self, X_train, Y_train):
        self.X_train = X_train
        self.Y_train = Y_train

    def predict_single(self, x):
        distances = [euclidean(x, x_train) for x_train in self.X_train]
        sorted_indices = np.argsort(distances)
        nearest_neighbors = [self.Y_train[i] for i in sorted_indices[:self.k]]
        return Counter(nearest_neighbors).most_common(1)[0][0]

    def predict(self, X_predict):
        return np.array([self.predict_single(x) for x in X_predict])

def accuracy(y_true, y_pred):
    return np.sum(y_true == y_pred) / len(y_true)
```

Then, a set of pytest tests for each function can be written as follows:

```python
import numpy as np
from knn import KNearestNeighbors, accuracy

def test_KNearestNeighbors():

    X_train = np.array([[2, 3], [4, 5], [5, 6], [1, 3]])
    Y_train = np.array([0, 1, 1, 0])
    X_test = np.array([[1, 2], [5, 7]])
    Y_test = np.array([0, 1])

    knn = KNearestNeighbors(k=3)
    knn.fit(X_train, Y_train)
    y_pred = knn.predict(X_test)

    assert y_pred[0] == Y_test[0]
    assert y_pred[1] == Y_test[1]

def test_accuracy():

    y_true = np.array([0, 1, 1, 0])
    y_pred1 = np.array([0, 1, 0, 0])
    y_pred2 = np.array([0, 1, 1, 1])

    accuracy1 = accuracy(y_true, y_pred1)
    accuracy2 = accuracy(y_true, y_pred2)

    assert accuracy1 == 0.75
    assert accuracy2 == 0.5
```